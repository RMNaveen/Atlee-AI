{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "PQvOcOMxHjn_"
      },
      "outputs": [],
      "source": [
        "# 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"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "2M-NpuOsrQ_1"
      },
      "outputs": [],
      "source": [
        "# !huggingface-cli login"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "QC95aM_prX70"
      },
      "outputs": [],
      "source": [
        "# !huggingface-cli whoami"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 177,
      "metadata": {
        "id": "CK8WTAD8LVid"
      },
      "outputs": [],
      "source": [
        "from dotenv import load_dotenv\n",
        "\n",
        "from pinecone import Pinecone, ServerlessSpec\n",
        "\n",
        "from langchain.memory import ConversationBufferMemory\n",
        "from langchain.chains import ConversationChain, LLMChain\n",
        "\n",
        "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
        "from langchain_pinecone import PineconeVectorStore\n",
        "from langchain.embeddings import HuggingFaceEmbeddings\n",
        "\n",
        "from langchain.docstore.document import Document\n",
        "\n",
        "from collections import Counter\n",
        "\n",
        "from typing import Any\n",
        "from pydantic import BaseModel\n",
        "from unstructured.partition.pdf import partition_pdf\n",
        "\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_core.documents import Document\n",
        "from langchain_core.runnables import RunnablePassthrough\n",
        "from langchain_core.prompts import PromptTemplate\n",
        "\n",
        "from langchain.retrievers.multi_vector import MultiVectorRetriever, SearchType\n",
        "from langchain.storage import InMemoryStore\n",
        "from langchain_anthropic import ChatAnthropic\n",
        "\n",
        "from tqdm.autonotebook import tqdm\n",
        "\n",
        "from langchain.llms import Ollama\n",
        "\n",
        "from PIL import Image\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "import anthropic\n",
        "import base64\n",
        "\n",
        "import uuid\n",
        "import io\n",
        "\n",
        "import time\n",
        "\n",
        "import os\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 210,
      "metadata": {},
      "outputs": [],
      "source": [
        "user_personas = {}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 211,
      "metadata": {},
      "outputs": [],
      "source": [
        "user_id = str(uuid.uuid4())\n",
        "user_personas[user_id] = {}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YtHz1dBjLmsR",
        "outputId": "03561eb3-d47c-49f4-ca3b-e63d8d31d84a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "c:\\Users\\HP\\Projects\\Python Projects\\GPT-3\\PDFAnalyzer\\.env\n"
          ]
        }
      ],
      "source": [
        "dir_path = os.path.join(os.path.dirname(os.getcwd()), 'PDFAnalyzer\\.env')\n",
        "print(dir_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aGQT8wf2PERB",
        "outputId": "10af287f-229d-4da5-9a66-134738a00cc5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "load_dotenv(dir_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 179,
      "metadata": {},
      "outputs": [],
      "source": [
        "interests = ''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 175,
      "metadata": {},
      "outputs": [],
      "source": [
        "# user_personas = {\n",
        "#     \"techenthusiast\": {\n",
        "#         \"name\": \"Faiyaz\",\n",
        "#         \"interests\": [\"technology\", \"gadgets\", \"programming\"],\n",
        "#         \"tone\": \"formal\",\n",
        "#         \"context\": \"Faiyaz is a tech enthusiast who enjoys learning about the latest innovations in technology.\"\n",
        "#     },\n",
        "#     \"art_lover\": {\n",
        "#         \"name\": \"Naveen\",\n",
        "#         \"interests\": [\"art\", \"painting\", \"design\"],\n",
        "#         \"tone\": \"casual\",\n",
        "#         \"context\": \"Naveen is an art lover who appreciates the beauty and creativity in various forms of art.\"\n",
        "#     },\n",
        "#     \"music_lover\": {\n",
        "#         \"name\": \"Nithish\",\n",
        "#         \"interests\": [\"love\", \"music\", \"music_production\"],\n",
        "#         \"tone\": \"funny\",\n",
        "#         \"context\": \"Nithish is an music lover who appreciates the music, music production and values love and romance.\"\n",
        "#     }\n",
        "# }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 332
        },
        "id": "7l9UbvX0NhE7",
        "outputId": "77b663a6-e388-4110-9d53-b4acb9c6eda7"
      },
      "outputs": [],
      "source": [
        "PINECONE_INDEX_NAME = os.environ['PINECONE_INDEX_NAME']\n",
        "PINECONE_API_KEY=os.environ['PINECONE_API_KEY']\n",
        "# ANTHROPIC_API_KEY=os.environ['ANTHROPIC_API_KEY']\n",
        "ANTHROPIC_API_KEY='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'\n",
        "LLAMA_API_KEY='LL-w5KOiBu1f11QJb7xYGk0iQ32LXkpt8pEdJmLrraHEDG6hg4h7E0XB5Kc5TygtEdJ'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "e7xg8RZJPyti"
      },
      "outputs": [],
      "source": [
        "EMBEDDING_MODEL='all-MiniLM-L6-v2'\n",
        "LLAMA_MODEL = \"meta-llama/Llama-2-7b-chat-hf\"\n",
        "CHAT_MODEL='claude-3-opus-20240229'\n",
        "FILE_NAME='sample.pdf'\n",
        "IMAGE_MEDIA_TYPE='image/jpeg'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "4xuu8vDaP-p-"
      },
      "outputs": [],
      "source": [
        "anthropic_client = anthropic.Anthropic(api_key=ANTHROPIC_API_KEY)\n",
        "# chat_model = ChatAnthropic(temperature=0.6, api_key=ANTHROPIC_API_KEY, model=CHAT_MODEL, default_headers={\"anthropic-beta\": \"tools-2024-04-04\"},)\n",
        "chat_model = Ollama(base_url=\"http://localhost:11434\", model=\"llama3\", temperature=0.7)\n",
        "embeddings = HuggingFaceEmbeddings(model_name=EMBEDDING_MODEL)\n",
        "pc = Pinecone(api_key=PINECONE_API_KEY)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 206,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_one_line_interest_from_history(search_titles):\n",
        "    prompt_text=\"\"\"\n",
        "    {search_titles}\n",
        "    \n",
        "    These are the recent search history titles of a person, give a concise overall interest of the above person in only one line.\n",
        "    \"\"\"\n",
        "    prompt = ChatPromptTemplate.from_template(prompt_text)\n",
        "    interest_chain = (\n",
        "        {\"search_titles\": lambda x : x}\n",
        "        | prompt\n",
        "        | chat_model\n",
        "        | StrOutputParser()\n",
        "    )\n",
        "    return interest_chain.invoke(search_titles)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 213,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_interests(df):\n",
        "    sorted_df = df.sort_values(by='Timestamp', ascending=False)\n",
        "    if len(sorted_df)>100:\n",
        "      nrows = len(sorted_df)/20\n",
        "      top_df = sorted_df.iloc[:nrows]\n",
        "    elif len(sorted_df)>10:\n",
        "      top_df = sorted_df.iloc[:10]\n",
        "    elif len(sorted_df)<10:\n",
        "      top_df = sorted_df.iloc[:len(sorted_df)]\n",
        "\n",
        "    interests = get_one_line_interest_from_history(top_df['Title'].tolist())\n",
        "    return interests"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 222,
      "metadata": {},
      "outputs": [],
      "source": [
        "df = pd.read_csv('out.csv')\n",
        "interests = get_interests(df)\n",
        "user_personas[user_id][\"web_interests\"] = interests"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "XfikBRGeQpAq"
      },
      "outputs": [],
      "source": [
        "class Element(BaseModel):\n",
        "    type: str\n",
        "    text: Any"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "wMQn3AKDQw_B"
      },
      "outputs": [],
      "source": [
        "def create_pinecone_index(index_name):\n",
        "    index_name = index_name\n",
        "    existing_indexes = [\n",
        "        index_info[\"name\"] for index_info in pc.list_indexes()\n",
        "    ]\n",
        "    if index_name not in existing_indexes:\n",
        "        pc.create_index(\n",
        "            index_name,\n",
        "            dimension=384,\n",
        "            metric='cosine',\n",
        "            spec=ServerlessSpec(\n",
        "                cloud=\"aws\",\n",
        "                region=\"us-east-1\",\n",
        "            ),\n",
        "        )\n",
        "        while not pc.describe_index(index_name).status['ready']:\n",
        "            time.sleep(1)\n",
        "\n",
        "    index = pc.Index(index_name)\n",
        "    time.sleep(1)\n",
        "    index.describe_index_stats()\n",
        "    return index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "9fr1BNr1Q3gm"
      },
      "outputs": [],
      "source": [
        "def get_text_elements(categorized_elements):\n",
        "    text_elements = [e for e in categorized_elements if e.type == \"text\"]\n",
        "    texts = [i.text for i in text_elements]\n",
        "    return texts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "oO0DA1YfQ7xN"
      },
      "outputs": [],
      "source": [
        "def get_table_elements(categorized_elements):\n",
        "    table_elements = [e for e in categorized_elements if e.type == \"table\"]\n",
        "    tables = [i.text for i in table_elements]\n",
        "    return tables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "Bgr3MuB23mzb"
      },
      "outputs": [],
      "source": [
        "def fetch_local_image(image_path):\n",
        "  try:\n",
        "    image = Image.open(image_path)\n",
        "\n",
        "    with io.BytesIO() as output:\n",
        "      image.save(output, format=\"JPEG\")\n",
        "      image_data = output.getvalue()\n",
        "\n",
        "    base64_encoded_image = base64.b64encode(image_data).decode(\"utf-8\")\n",
        "    return base64_encoded_image\n",
        "\n",
        "  except FileNotFoundError:\n",
        "    raise FileNotFoundError(f\"Image file not found: {image_path}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "tXCqWMPQ6lQp"
      },
      "outputs": [],
      "source": [
        "def get_image_summaries_from_anthropic(image_media_type, local_image):\n",
        "  message = anthropic_client.messages.create(\n",
        "      model=\"claude-3-opus-20240229\",\n",
        "      max_tokens=1024,\n",
        "      messages=[\n",
        "          {\n",
        "              \"role\": \"user\",\n",
        "              \"content\": [\n",
        "                  {\n",
        "                      \"type\": \"image\",\n",
        "                      \"source\": {\n",
        "                          \"type\": \"base64\",\n",
        "                          \"media_type\": image_media_type,\n",
        "                          \"data\": local_image,\n",
        "                      },\n",
        "                  },\n",
        "                  {\n",
        "                      \"type\": \"text\",\n",
        "                      \"text\": \"Describe this image in one line.\"\n",
        "                  }\n",
        "              ],\n",
        "          }\n",
        "        ],\n",
        "      )\n",
        "  return message"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "03EyyQiA3Dof"
      },
      "outputs": [],
      "source": [
        "def get_image_summaries():\n",
        "  image_summaries = []\n",
        "  image_path = os.getcwd() + '\\\\figures'\n",
        "  for images in os.listdir(image_path):\n",
        "    if not os.path.isdir(images):\n",
        "      try:\n",
        "        local_image = fetch_local_image(image_path + images)\n",
        "        image_summary = get_image_summaries_from_anthropic(IMAGE_MEDIA_TYPE, local_image)\n",
        "        image_summaries.append(image_summary.content[0].text)\n",
        "      except FileNotFoundError as e:\n",
        "        print(f\"Error: {e}\")\n",
        "  return image_summaries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "OBp-AZ3cayFi"
      },
      "outputs": [],
      "source": [
        "def get_overall_summary(raw_data):\n",
        "  prompt_text=\"\"\"\n",
        "  You are an assistant tasked with summarizing the give data which may include tables/text. \\\n",
        "  Give a concise summary of the data. Table or Text chunk: {data}\n",
        "  \"\"\"\n",
        "  prompt = ChatPromptTemplate.from_template(prompt_text)\n",
        "  summary_chain = (\n",
        "      {\"data\": lambda x : x}\n",
        "      | prompt\n",
        "      | chat_model\n",
        "      | StrOutputParser()\n",
        "  )\n",
        "  return summary_chain.batch(raw_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "Mzd9nef6Q_Jk"
      },
      "outputs": [],
      "source": [
        "def store_pdf_in_pinecone(file_name, index_name, embeddings):\n",
        "    raw_pdf_elements = partition_pdf(\n",
        "        filename=file_name,\n",
        "        extract_images_in_pdf=True,\n",
        "        infer_table_structure=True,\n",
        "        chunking_strategy=\"by_title\",\n",
        "        image_output_dir_path='',\n",
        "    )\n",
        "\n",
        "    print(\"Elements in the PDF: \", end='\\n')\n",
        "    print(Counter(type(element) for element in raw_pdf_elements), end='\\n')\n",
        "\n",
        "    categorized_elements = []\n",
        "    for element in raw_pdf_elements:\n",
        "        categorized_elements.append(Element(type=\"text\", text=str(element)))\n",
        "\n",
        "    id_key = 'doc_id'\n",
        "\n",
        "    texts = get_text_elements(categorized_elements)\n",
        "    tables = get_table_elements(categorized_elements)\n",
        "    img_summaries = get_image_summaries()\n",
        "\n",
        "    text_summaries = get_overall_summary(texts)\n",
        "    table_summaries = get_overall_summary(tables)\n",
        "\n",
        "    text_data = texts + text_summaries\n",
        "    table_data = tables + table_summaries\n",
        "\n",
        "    doc_ids = [str(uuid.uuid4()) for _ in text_data]\n",
        "    table_ids = [str(uuid.uuid4()) for _ in table_data]\n",
        "    img_ids = [str(uuid.uuid4()) for _ in img_summaries]\n",
        "\n",
        "    text_docs = [\n",
        "        Document(page_content=s, metadata={id_key: doc_ids[i]})\n",
        "        for i, s in enumerate(text_data)\n",
        "    ]\n",
        "\n",
        "    table_docs = [\n",
        "        Document(page_content=s, metadata={id_key: table_ids[i]})\n",
        "        for i, s in enumerate(table_data)\n",
        "    ]\n",
        "\n",
        "    img_summary_docs = [\n",
        "        Document(page_content=s, metadata={id_key: img_ids[i]})\n",
        "        for i, s in enumerate(img_ids)\n",
        "    ]\n",
        "\n",
        "    vector_store = PineconeVectorStore(embedding=embeddings, index_name=index_name)\n",
        "    store = InMemoryStore()\n",
        "\n",
        "    retriever = MultiVectorRetriever(\n",
        "        vectorstore=vector_store,\n",
        "        docstore=store,\n",
        "        id_key=id_key,\n",
        "    )\n",
        "\n",
        "    vector_store.add_documents(text_docs)\n",
        "    retriever.docstore.mset(\n",
        "        list(\n",
        "            zip(\n",
        "                doc_ids, text_data\n",
        "            )\n",
        "        )\n",
        "    )\n",
        "\n",
        "    vector_store.add_documents(table_docs)\n",
        "    retriever.docstore.mset(\n",
        "        list(\n",
        "            zip(\n",
        "                table_ids, table_data\n",
        "            )\n",
        "        )\n",
        "    )\n",
        "\n",
        "    vector_store.add_documents(img_summary_docs)\n",
        "    retriever.docstore.mset(\n",
        "        list(\n",
        "            zip(\n",
        "                img_ids, img_summaries\n",
        "            )\n",
        "        )\n",
        "    )\n",
        "\n",
        "    return retriever"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 229,
      "metadata": {
        "id": "WiP0ZUpHRG5K"
      },
      "outputs": [],
      "source": [
        "def get_personalized_output(question, retriever, chat_model, user_personas, user_id):\n",
        "    user_persona = user_personas[user_id]\n",
        "    \n",
        "    prompt_template=\"\"\"\n",
        "    Answer the question based on the following context, which can include text and tables:\n",
        "    {context}\n",
        "    \n",
        "    Question:\n",
        "    {question}\n",
        "    \n",
        "    Explain to the below user,\n",
        "    {interests}\n",
        "    \n",
        "    Give personalized answer to the above person.\n",
        "    \"\"\"\n",
        "    \n",
        "    prompt = PromptTemplate(\n",
        "        input_variables=[\n",
        "            \"context\", \n",
        "            \"question\",\n",
        "            \"interests\",\n",
        "        ],\n",
        "        template=prompt_template,\n",
        "    )\n",
        "    \n",
        "    memory=ConversationBufferMemory(\n",
        "        memory_key=\"chat_history\",\n",
        "        input_key=\"question\",\n",
        "    )\n",
        "    \n",
        "    chain = LLMChain(\n",
        "        llm=chat_model,\n",
        "        prompt=prompt,\n",
        "        verbose=False,\n",
        "        memory=memory,\n",
        "    )\n",
        "\n",
        "    result = chain.invoke(\n",
        "        {\n",
        "            \"interests\": user_persona[\"web_interests\"],\n",
        "            \"context\": retriever,\n",
        "            \"question\": question,\n",
        "        },\n",
        "        return_only_outputs=True\n",
        "    )\n",
        "    return result[\"text\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 230,
      "metadata": {
        "id": "mZ8tGLYRROGD"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "This function will be deprecated in a future release and `unstructured` will simply use the DEFAULT_MODEL from `unstructured_inference.model.base` to set default model name\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Elements in the PDF: \n",
            "Counter({<class 'unstructured.documents.elements.CompositeElement'>: 4})\n",
            "Elements in the PDF - Categorized: \n",
            "[Element(type='text', text='Functional Resume Sample\\n\\nJohn W. Smith 2002 Front Range Way Fort Collins, CO 80525 jwsmith@colostate.edu\\n\\nCareer Summary\\n\\nFour years experience in early childhood development with a diverse background in the care of special needs children and adults.\\n\\nAdult Care Experience\\n\\nDetermined work placement for 150 special needs adult clients. • Maintained client databases and records. • Coordinated client contact with local health care professionals on a monthly basis. • Managed 25 volunteer workers.'), Element(type='text', text='Childcare Experience\\n\\nCoordinated service assignments for 20 part-time counselors and 100 client families. • Oversaw daily activity and outing planning for 100 clients. • Assisted families of special needs clients with researching financial assistance and\\n\\nhealthcare.\\n\\nAssisted teachers with managing daily classroom activities. • Oversaw daily and special student activities.'), Element(type='text', text='Employment History\\n\\n1999-2002 Counseling Supervisor, The Wesley Center, Little Rock, Arkansas.\\n\\n1999-2002 1997-1999 1996-1997\\n\\nCounseling Supervisor, The Wesley Center, Little Rock, Arkansas. Client Specialist, Rainbow Special Care Center, Little Rock, Arkansas Teacher’s Assistant, Cowell Elementary, Conway, Arkansas'), Element(type='text', text='Education\\n\\nUniversity of Arkansas at Little Rock, Little Rock, AR\\n\\nBS in Early Childhood Development (1999) • BA in Elementary Education (1998) • GPA (4.0 Scale): Early Childhood Development – 3.8, Elementary Education – 3.5,\\n\\nOverall 3.4.\\n\\n• Dean’s List, Chancellor’s List')]\n",
            "Summaries:\n",
            "\n",
            "\n",
            "['Here is a concise summary of the data:\\n\\nJohn W. Smith has four years of experience in early childhood development, specifically working with special needs children and adults. His career highlights include determining work placements for 150 adult clients, maintaining client records, coordinating healthcare professional contacts, and managing 25 volunteer workers.', 'Here is a concise summary of the data:\\n\\nThe childcare experience involved coordinating services for 20 part-time counselors and 100 client families. The assistant oversaw daily activity planning, including outings, for the clients. Additionally, they assisted families with researching financial assistance and healthcare options for special needs clients. Furthermore, they supported teachers in managing classroom activities and overseeing daily and special student events.', \"Here is a concise summary of the employment history:\\n\\nFrom 1999 to 2002, this individual held three positions: Counseling Supervisor at The Wesley Center in Little Rock, Arkansas; Client Specialist at Rainbow Special Care Center also in Little Rock; and Teacher's Assistant at Cowell Elementary School in Conway, Arkansas.\", \"Here is a concise summary of the education data:\\n\\nThe individual holds a Bachelor's degree in Early Childhood Development (1999) and a Bachelor's degree in Elementary Education (1998) from University of Arkansas at Little Rock. The overall GPA was 3.4 on a 4.0 scale, with separate GPAs of 3.8 in Early Childhood Development and 3.5 in Elementary Education. Additionally, the individual achieved Dean's List and Chancellor's List honors during their academic career.\"]\n",
            "[]\n"
          ]
        }
      ],
      "source": [
        "pinecone_index = create_pinecone_index(PINECONE_INDEX_NAME)\n",
        "retriever = store_pdf_in_pinecone(FILE_NAME, PINECONE_INDEX_NAME, embeddings)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 231,
      "metadata": {
        "id": "3uNLXvw6hWRc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['Here is a concise summary of the data:\\n\\nThe data appears to be related to programming, software development, and technical skills. The categories include:\\n\\n* Programming languages: C/C++ basics, Dart\\n* Tools/Frameworks/Libraries: Pandas/Matplotlib/NumPy, Django/Flask/React/NodeJS\\n* Databases: MySQL/MongoDB, SQL Server/Redis, Postgres/Firebase\\n* Non-technical skills: Leadership, Problem Solving, Communication Skills\\n* Other technical skills: HTML/CSS/SASS/Bootstrap, Git/Docker/Linux/OpenCV\\n\\nThere is also a mention of PROJECT AND RESEARCH EXPERIENCE, which suggests that the individual has hands-on experience in software development and research projects.', \"Here's a concise summary of the experience:\\n\\n**Software Engineer (Backend)**: Worked at Applied Data Finance Pvt Ltd in India from June 2021 to August 2023. Key responsibilities included designing and implementing high-performance web applications using Redis caching for scalability and improving response times while performing financial data analysis with tools like Pandas, Flask, and FastAPI.\", 'Functional Resume Sample\\n\\nJohn W. Smith 2002 Front Range Way Fort Collins, CO 80525 jwsmith@colostate.edu\\n\\nCareer Summary\\n\\nFour years experience in early childhood development with a diverse background in the care of special needs children and adults.\\n\\nAdult Care Experience\\n\\nDetermined work placement for 150 special needs adult clients. • Maintained client databases and records. • Coordinated client contact with local health care professionals on a monthly basis. • Managed 25 volunteer workers.', 'Here is a concise summary of the experience:\\n\\nThe individual worked as a Software Engineer (Backend) at Applied Data Finance Pvt Ltd in India from June 2021 to August 2023. Their key responsibilities included designing and implementing high-performance web applications for Personify Financial using Redis caching to ensure scalability and improve response times while performing financial data analysis.']\n"
          ]
        }
      ],
      "source": [
        "query = \"Mention the Work Experience present\"\n",
        "retriever.search_type = SearchType.mmr\n",
        "response = retriever.vectorstore.similarity_search(query)\n",
        "response = [response[i].page_content for i in range(len(response))]\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 232,
      "metadata": {
        "id": "lt2sLEo-Yke_"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hi there!\n",
            "\n",
            "I noticed you're interested in online gaming, checking emails, and following sports news. I'll give you a quick rundown of the work experience mentioned earlier.\n",
            "\n",
            "The individual worked as a Software Engineer (Backend) at Applied Data Finance Pvt Ltd in India from June 2021 to August 2023. Their key responsibilities included:\n",
            "\n",
            "* Designing and implementing high-performance web applications for financial data analysis using Redis caching\n",
            "* Improving response times while performing financial data analysis with tools like Pandas, Flask, and FastAPI\n",
            "\n",
            "As someone who enjoys online gaming and sports news, you might appreciate the individual's experience in working on high-performance web applications. Who knows, maybe their skills will one day be used to develop an amazing new game or platform for fans of your favorite sport!\n",
            "\n",
            "Feel free to ask me any more questions or share your own interests, and I'll do my best to help!\n"
          ]
        }
      ],
      "source": [
        "result = get_personalized_output(query, response, chat_model, user_personas, user_id)\n",
        "print(result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 233,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Based on the provided context, I'd say that this individual is more focused on programming, software development, and technical skills rather than playing online games or following sports news. They seem to have hands-on experience in software engineering and research projects.\n",
            "\n",
            "If you're interested in online gaming, checking email, or following sports news, you might want to consider exploring related fields like game development, data analysis, or journalism. Who knows, maybe their technical skills can even help them create a personalized gaming platform or analyze sports data!\n",
            "\n",
            "Feel free to ask me any questions about programming, software development, or research projects. I'm here to help!\n"
          ]
        }
      ],
      "source": [
        "query = \"Make the above response concise\"\n",
        "result = get_personalized_output(query, response, chat_model, user_personas, user_id)\n",
        "print(result)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "gpuType": "V28",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
